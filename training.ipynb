{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "58e616b018b16151b19a22e3317ed63cc4180af6ad7f4c88f207a4b9614d3db8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('trainingData.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  Sentiment\n",
       "0               Is 3M (MMM) A Good Stock To Buy Now?          1\n",
       "1  3 Dividend Stocks That Should Pay You the Rest...          1\n",
       "2  Starbucks and Disney Are Stock Stalwarts That ...          1\n",
       "3  The 10 Most Reliable Value Stocks to Buy for 2021          1\n",
       "4                                 Is GE Stock a Buy?          1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Is 3M (MMM) A Good Stock To Buy Now?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3 Dividend Stocks That Should Pay You the Rest...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Starbucks and Disney Are Stock Stalwarts That ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The 10 Most Reliable Value Stocks to Buy for 2021</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Is GE Stock a Buy?</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(df['title'].values)\n",
    "train_y = np.array(df['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "print(train_dataset.element_spec)\n",
    "# print(test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "title        object\n",
       "Sentiment     int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].astype(str)\n",
    "# split = 8000\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ((df['title']),\n",
    "    (df['Sentiment']))\n",
    ")\n",
    "\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     ((df['title'][split:]),\n",
    "#     (df['Sentiment'][split:]))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "# print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.element_spec)\n",
    "# print(test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text:  b'Is 3M (MMM) A Good Stock To Buy Now?'\nlabel:  1\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "texts:  [b'Is Corteva Inc (CTVA) Stock Near the Top of the Agricultural Inputs Industry?'\n b'Cramer Gives His Opinion On Barrick Gold, Las Vegas Sands And More'\n b'FMC Corp (FMC) Stock Increases 3.25% This Week; Should You Buy?']\n\nlabels:  [ 1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=5000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'stock', 'to', 'the', 'is', 'a', 'stocks', 'buy',\n",
       "       'for', 'in', 'and', 'inc', 'of', 'earnings', 'now', 'why', 'on',\n",
       "       'good', 'you'], dtype='<U20')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   5,  906,   12, 1356,    2,  333,    4,   31,   13,    4, 4653,\n",
       "           1,  138,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [ 153, 2072, 1083, 2591,   17,    1,  897, 2297, 1937, 3032,   11,\n",
       "          56,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0],\n",
       "       [ 536,   75,  536,    2, 1320, 3524,   26,   90,   20,   19,    8,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original:  b'Is Corteva Inc (CTVA) Stock Near the Top of the Agricultural Inputs Industry?'\nRound-trip:  is corteva inc ctva stock near the top of the agricultural [UNK] industry             \n\nOriginal:  b'Cramer Gives His Opinion On Barrick Gold, Las Vegas Sands And More'\nRound-trip:  cramer gives his opinion on [UNK] gold las vegas sands and more              \n\nOriginal:  b'FMC Corp (FMC) Stock Increases 3.25% This Week; Should You Buy?'\nRound-trip:  fmc corp fmc stock increases 325 this week should you buy               \n\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[False, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.01273567]\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('It is a Bad stock')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/128\n",
      "143/143 [==============================] - 2s 15ms/step - loss: 0.4285 - accuracy: 0.0000e+00\n",
      "Epoch 2/128\n",
      "143/143 [==============================] - 2s 15ms/step - loss: -0.6588 - accuracy: 0.0000e+00\n",
      "Epoch 3/128\n",
      "143/143 [==============================] - 2s 15ms/step - loss: -3.6428 - accuracy: 0.0635\n",
      "Epoch 4/128\n",
      "143/143 [==============================] - 2s 15ms/step - loss: -7.5649 - accuracy: 0.1870\n",
      "Epoch 5/128\n",
      "143/143 [==============================] - 2s 15ms/step - loss: -12.4773 - accuracy: 0.2372\n",
      "Epoch 6/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -18.0466 - accuracy: 0.2739\n",
      "Epoch 7/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -23.9587 - accuracy: 0.2963\n",
      "Epoch 8/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -30.8711 - accuracy: 0.3048\n",
      "Epoch 9/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -38.3064 - accuracy: 0.3273\n",
      "Epoch 10/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -46.5604 - accuracy: 0.3354\n",
      "Epoch 11/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -55.3025 - accuracy: 0.3545\n",
      "Epoch 12/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -65.1136 - accuracy: 0.3504\n",
      "Epoch 13/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -74.9437 - accuracy: 0.3669\n",
      "Epoch 14/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -85.8848 - accuracy: 0.3719\n",
      "Epoch 15/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -97.1344 - accuracy: 0.3777\n",
      "Epoch 16/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -109.3379 - accuracy: 0.3870\n",
      "Epoch 17/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -121.3858 - accuracy: 0.3838\n",
      "Epoch 18/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -133.5261 - accuracy: 0.3878\n",
      "Epoch 19/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -144.9420 - accuracy: 0.3897\n",
      "Epoch 20/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -157.3881 - accuracy: 0.3965\n",
      "Epoch 21/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -172.0796 - accuracy: 0.3939\n",
      "Epoch 22/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -185.0416 - accuracy: 0.4000\n",
      "Epoch 23/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -199.3574 - accuracy: 0.3993\n",
      "Epoch 24/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -213.5911 - accuracy: 0.4017\n",
      "Epoch 25/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -229.9002 - accuracy: 0.4057\n",
      "Epoch 26/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -244.7542 - accuracy: 0.4024\n",
      "Epoch 27/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -258.6265 - accuracy: 0.4045\n",
      "Epoch 28/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -274.9837 - accuracy: 0.4063\n",
      "Epoch 29/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -294.2828 - accuracy: 0.4079\n",
      "Epoch 30/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -309.4849 - accuracy: 0.4099\n",
      "Epoch 31/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -327.3922 - accuracy: 0.4072\n",
      "Epoch 32/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -344.7270 - accuracy: 0.4067\n",
      "Epoch 33/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -361.7386 - accuracy: 0.4083\n",
      "Epoch 34/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -379.2036 - accuracy: 0.4101\n",
      "Epoch 35/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -396.2508 - accuracy: 0.4120\n",
      "Epoch 36/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -422.5342 - accuracy: 0.4134\n",
      "Epoch 37/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -439.5695 - accuracy: 0.4134\n",
      "Epoch 38/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -461.4299 - accuracy: 0.4143\n",
      "Epoch 39/128\n",
      "143/143 [==============================] - 4s 26ms/step - loss: -478.1181 - accuracy: 0.4145\n",
      "Epoch 40/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -501.3691 - accuracy: 0.4141\n",
      "Epoch 41/128\n",
      "143/143 [==============================] - 4s 25ms/step - loss: -522.1501 - accuracy: 0.4136\n",
      "Epoch 42/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -542.8336 - accuracy: 0.4149\n",
      "Epoch 43/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -564.2947 - accuracy: 0.4152\n",
      "Epoch 44/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -591.8895 - accuracy: 0.4162\n",
      "Epoch 45/128\n",
      "143/143 [==============================] - 4s 25ms/step - loss: -605.1212 - accuracy: 0.4122\n",
      "Epoch 46/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -634.6404 - accuracy: 0.4142\n",
      "Epoch 47/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -654.5851 - accuracy: 0.4154\n",
      "Epoch 48/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -682.0019 - accuracy: 0.4164\n",
      "Epoch 49/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -704.5657 - accuracy: 0.4145\n",
      "Epoch 50/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -724.2521 - accuracy: 0.4144\n",
      "Epoch 51/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -752.8798 - accuracy: 0.4158\n",
      "Epoch 52/128\n",
      "143/143 [==============================] - 3s 23ms/step - loss: -775.0952 - accuracy: 0.4168\n",
      "Epoch 53/128\n",
      "143/143 [==============================] - 4s 25ms/step - loss: -803.8962 - accuracy: 0.4146\n",
      "Epoch 54/128\n",
      "143/143 [==============================] - 4s 26ms/step - loss: -827.0361 - accuracy: 0.4120\n",
      "Epoch 55/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -851.1348 - accuracy: 0.4138\n",
      "Epoch 56/128\n",
      "143/143 [==============================] - 4s 31ms/step - loss: -876.3414 - accuracy: 0.4132\n",
      "Epoch 57/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -897.9312 - accuracy: 0.4158\n",
      "Epoch 58/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -931.5843 - accuracy: 0.4153\n",
      "Epoch 59/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -953.6108 - accuracy: 0.4147\n",
      "Epoch 60/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -978.8013 - accuracy: 0.4171\n",
      "Epoch 61/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -1011.2657 - accuracy: 0.4184\n",
      "Epoch 62/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -1039.6300 - accuracy: 0.4146\n",
      "Epoch 63/128\n",
      "143/143 [==============================] - 5s 33ms/step - loss: -1078.9275 - accuracy: 0.4206\n",
      "Epoch 64/128\n",
      "143/143 [==============================] - 8s 54ms/step - loss: -1099.1329 - accuracy: 0.4195\n",
      "Epoch 65/128\n",
      "143/143 [==============================] - 8s 58ms/step - loss: -1134.4701 - accuracy: 0.4178\n",
      "Epoch 66/128\n",
      "143/143 [==============================] - 9s 60ms/step - loss: -1165.2501 - accuracy: 0.4164\n",
      "Epoch 67/128\n",
      "143/143 [==============================] - 9s 66ms/step - loss: -1194.6056 - accuracy: 0.4195\n",
      "Epoch 68/128\n",
      "143/143 [==============================] - 9s 60ms/step - loss: -1220.8622 - accuracy: 0.4167\n",
      "Epoch 69/128\n",
      "143/143 [==============================] - 8s 59ms/step - loss: -1259.8014 - accuracy: 0.4190\n",
      "Epoch 70/128\n",
      "143/143 [==============================] - 8s 55ms/step - loss: -1288.5249 - accuracy: 0.4165\n",
      "Epoch 71/128\n",
      "143/143 [==============================] - 7s 51ms/step - loss: -1298.4561 - accuracy: 0.4144\n",
      "Epoch 72/128\n",
      "143/143 [==============================] - 7s 51ms/step - loss: -1346.4342 - accuracy: 0.4168\n",
      "Epoch 73/128\n",
      "143/143 [==============================] - 8s 57ms/step - loss: -1380.7527 - accuracy: 0.4138\n",
      "Epoch 74/128\n",
      "143/143 [==============================] - 10s 67ms/step - loss: -1413.3558 - accuracy: 0.4169\n",
      "Epoch 75/128\n",
      "143/143 [==============================] - 8s 57ms/step - loss: -1444.2944 - accuracy: 0.4157\n",
      "Epoch 76/128\n",
      "143/143 [==============================] - 9s 64ms/step - loss: -1488.3082 - accuracy: 0.4166\n",
      "Epoch 77/128\n",
      "143/143 [==============================] - 9s 64ms/step - loss: -1516.4573 - accuracy: 0.4169\n",
      "Epoch 78/128\n",
      "143/143 [==============================] - 9s 62ms/step - loss: -1558.1235 - accuracy: 0.4156\n",
      "Epoch 79/128\n",
      "143/143 [==============================] - 10s 69ms/step - loss: -1570.0436 - accuracy: 0.4108\n",
      "Epoch 80/128\n",
      "143/143 [==============================] - 8s 59ms/step - loss: -1606.5658 - accuracy: 0.4074\n",
      "Epoch 81/128\n",
      "143/143 [==============================] - 7s 51ms/step - loss: -1644.2648 - accuracy: 0.4052\n",
      "Epoch 82/128\n",
      "143/143 [==============================] - 8s 59ms/step - loss: -1675.9290 - accuracy: 0.4029\n",
      "Epoch 83/128\n",
      "143/143 [==============================] - 9s 60ms/step - loss: -1720.1526 - accuracy: 0.4059\n",
      "Epoch 84/128\n",
      "143/143 [==============================] - 8s 54ms/step - loss: -1753.9379 - accuracy: 0.4097\n",
      "Epoch 85/128\n",
      "143/143 [==============================] - 9s 66ms/step - loss: -1785.3529 - accuracy: 0.4057\n",
      "Epoch 86/128\n",
      "143/143 [==============================] - 7s 51ms/step - loss: -1815.0437 - accuracy: 0.4074\n",
      "Epoch 87/128\n",
      "143/143 [==============================] - 8s 57ms/step - loss: -1865.6849 - accuracy: 0.4058\n",
      "Epoch 88/128\n",
      "143/143 [==============================] - 9s 63ms/step - loss: -1901.0469 - accuracy: 0.4031\n",
      "Epoch 89/128\n",
      "143/143 [==============================] - 7s 50ms/step - loss: -1941.3883 - accuracy: 0.4053\n",
      "Epoch 90/128\n",
      "143/143 [==============================] - 9s 64ms/step - loss: -1984.4255 - accuracy: 0.4064\n",
      "Epoch 91/128\n",
      "143/143 [==============================] - 9s 61ms/step - loss: -2026.2700 - accuracy: 0.4044\n",
      "Epoch 92/128\n",
      "143/143 [==============================] - 8s 59ms/step - loss: -2055.0334 - accuracy: 0.3992\n",
      "Epoch 93/128\n",
      "143/143 [==============================] - 8s 56ms/step - loss: -2093.1257 - accuracy: 0.4054\n",
      "Epoch 94/128\n",
      "143/143 [==============================] - 7s 50ms/step - loss: -2126.6331 - accuracy: 0.4007\n",
      "Epoch 95/128\n",
      "143/143 [==============================] - 6s 39ms/step - loss: -2168.8940 - accuracy: 0.3968\n",
      "Epoch 96/128\n",
      "143/143 [==============================] - 6s 40ms/step - loss: -2191.3335 - accuracy: 0.3921\n",
      "Epoch 97/128\n",
      "143/143 [==============================] - 5s 35ms/step - loss: -2225.7510 - accuracy: 0.3937\n",
      "Epoch 98/128\n",
      "143/143 [==============================] - 5s 32ms/step - loss: -2278.7517 - accuracy: 0.3946\n",
      "Epoch 99/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -2325.8687 - accuracy: 0.3996\n",
      "Epoch 100/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -2360.2515 - accuracy: 0.3903\n",
      "Epoch 101/128\n",
      "143/143 [==============================] - 4s 26ms/step - loss: -2404.1562 - accuracy: 0.3869\n",
      "Epoch 102/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -2443.7927 - accuracy: 0.3908\n",
      "Epoch 103/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -2481.5999 - accuracy: 0.3905\n",
      "Epoch 104/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -2525.4343 - accuracy: 0.3936\n",
      "Epoch 105/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -2582.0657 - accuracy: 0.3943\n",
      "Epoch 106/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -2638.1250 - accuracy: 0.3941\n",
      "Epoch 107/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -2673.1133 - accuracy: 0.3953\n",
      "Epoch 108/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -2722.1377 - accuracy: 0.3975\n",
      "Epoch 109/128\n",
      "143/143 [==============================] - 4s 30ms/step - loss: -2757.9626 - accuracy: 0.3966\n",
      "Epoch 110/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -2820.5037 - accuracy: 0.3924\n",
      "Epoch 111/128\n",
      "143/143 [==============================] - 4s 25ms/step - loss: -2857.5938 - accuracy: 0.3925\n",
      "Epoch 112/128\n",
      "143/143 [==============================] - 3s 24ms/step - loss: -2884.8274 - accuracy: 0.3902\n",
      "Epoch 113/128\n",
      "143/143 [==============================] - 4s 25ms/step - loss: -2942.6333 - accuracy: 0.3926\n",
      "Epoch 114/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -2998.0320 - accuracy: 0.3876\n",
      "Epoch 115/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -3038.6938 - accuracy: 0.3915\n",
      "Epoch 116/128\n",
      "143/143 [==============================] - 4s 27ms/step - loss: -3089.9365 - accuracy: 0.3901\n",
      "Epoch 117/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -3116.9797 - accuracy: 0.3919\n",
      "Epoch 118/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -3175.1653 - accuracy: 0.3865\n",
      "Epoch 119/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -3206.7634 - accuracy: 0.3894\n",
      "Epoch 120/128\n",
      "143/143 [==============================] - 4s 28ms/step - loss: -3275.6670 - accuracy: 0.3956\n",
      "Epoch 121/128\n",
      "143/143 [==============================] - 4s 31ms/step - loss: -3337.8340 - accuracy: 0.3969\n",
      "Epoch 122/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -3369.4971 - accuracy: 0.3892\n",
      "Epoch 123/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -3436.9846 - accuracy: 0.3910\n",
      "Epoch 124/128\n",
      "143/143 [==============================] - 4s 29ms/step - loss: -3466.5544 - accuracy: 0.3926\n",
      "Epoch 125/128\n",
      "143/143 [==============================] - 6s 42ms/step - loss: -3509.0959 - accuracy: 0.3917\n",
      "Epoch 126/128\n",
      "143/143 [==============================] - 8s 55ms/step - loss: -3586.3716 - accuracy: 0.3877\n",
      "Epoch 127/128\n",
      "143/143 [==============================] - 8s 55ms/step - loss: -3596.2664 - accuracy: 0.3840\n",
      "Epoch 128/128\n",
      "143/143 [==============================] - 8s 53ms/step - loss: -3648.5598 - accuracy: 0.3862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "# print('Test Loss: {}'.format(test_loss))\n",
    "# print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,8))\n",
    "# plt.subplot(1,2,1)\n",
    "# plot_graphs(history, 'accuracy')\n",
    "# plt.ylim(None,1)\n",
    "# plt.subplot(1,2,2)\n",
    "# plot_graphs(history, 'loss')\n",
    "# plt.ylim(0,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ('Bad Buy')\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-8766.751]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}